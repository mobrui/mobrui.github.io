---
title: '''大模型小组2025第一次讨论'''
date: 2025-03-05 07:43:12
tags:
---

# 深入浅出ai绘画

## 1 神经网络部分

让我们来从最简单的数字识别神经网络说起，

其像素灰度值的输入，给出自己像素的预测结果（1 - 9）

对于层与层之间的联系 我们使用一种函数 （权重，偏差 约束） 这在下文会说到

大家觉得这一系列名词可能比较复杂难懂 让我们举一个简单的例子

![image-20250306182451051](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306182451051.png)

我们来看这张图片 其由784个像素点构成 我们把像素点的灰度值作为输入来传递给下一层 那么其满足什么样的函数关系才能合理的传达图像的一些信息呢？？

答案是我们不知道，但是依据之前我们对神经网络中神经元的理解。 我们让机器随机的赋予不同节点之间的权重（有正有负）（之后通过训练一步一步的改进）。所以现在我们的计算机就会给我们一些预测结果（最后曾）表现为一些权重，显然，随机的权重是不符合我们要求的。

![image-20250306164410253](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306164410253.png)

所以我们要进行调整，调整必然要有一个参照，否则机器就不会知道调整到什么程度才是好的。

因此我们引入了一个代价函数，来计算预测结果和我们实际结果之间的偏差，偏差越小，说明机器的预测越准确，我们不妨把这个偏差叫做**代价**。

![image-20250306184112720](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306184112720.png)

我们先入为主的给大家一个概念，对函数求导可以得到一个导数，导数指导着我们的变量要朝着什么方向调整才能让我们目前的函数值接近局部的最小值（你可以类比成小球），那么对于我们的代价函数，只不过是元素多了亿点点。道理是一样的，自变量就是我们的权重，改变的函数值变成了我们的代价（我还没学过二元导数所以可能理解也不是太过于深刻）

![image-20250306183510951](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306183510951.png)

衔接上文，机器通过当前层的数值根据代价来调整上一层的权重值我们就叫做反向传播算法。

通过反向传播算法来一层一层的调整参数 so？机器是如何调整参数的呢？

![image-20250306165025183](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306165025183.png)



![image-20250306160631759](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306160631759.png)





## 2 Transformer之我见

![image-20250307104100190](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307104100190.png)

![image-20250307102034347](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307102034347.png)

###  2.1 token和单头注意力

即为分割出来的小块 我们用向量来表示   这些初始化的向量首先包含了其在文中的位置信息，剩下的就是它的初始含义我们不妨把它转换成“一个token对应一个单词”这样简明的理解方法，经过预训练，每个单词在数据库中都对应一个向量。

![image-20250306233847941](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250306233847941.png)

而其就可以抽象为高维空间内的一个点，不同的维度代表不同的性质。

![image-20250307063851773](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307063851773.png)

接下来我们把句子组成的矩阵导入注意力模块，在这里，机器会结合上下文来调整每个列向量的值（结合上下文） 因为一个词可能有多个含义 比如 bug可以指bug也可以指小虫子

![image-20250307064048904](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307064048904.png)

所以我们需要的其实是一个向量，表示当前单词需要向什么方向移动才能更符合我们的上下文。

![image-20250307063911150](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307063911150.png)

下面让我们来看看机器是怎么进行计算的 

### 询问

看途中的例子，矩阵进行提问，问我的前面是不是有形容词呢？

通过矩阵乘法我们得出一个新的向量来表示问题（所以问题只会和前文交互）

![image-20250307064617397](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307064617397.png)

### 键值

接下来我们对每一个词来定性（回答问题）

![image-20250307095910641](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307095910641.png)

询问和键值两个矩阵就产生了两个向量，我们知道点积可以表示向量的接近性，点积越大就代表越相关（向对应的方向移动）

![image-20250307100104935](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307100104935.png)

![image-20250307065439110](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307065439110.png)

为了使数据更平滑 我们先对原始数据进行一些处理，然后采用softmax函数来限制范围和sum和 最后我们把左边的列乘上一个value向量(名字很直观啊 把值 Value 表示出来)

![image-20250307070009854](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307070009854.png)

这里的T代表转置

![image-20250307070428565](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307070428565.png)

这个东西就很直观了 转置相乘才能让对应的数据对应！

![image-20250307071922359](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307071922359.png)

![image-20250307101125459](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307101125459.png)

最后 注意力机制让我们达成了类似这样的效果

![image-20250307100940783](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307100940783.png)

其让每一个token都充分吸收了上下文的养分！使其达到类似于我们上下文中描述的形象（把更多信息嵌入原始向量）

最后 真正的GPT其实是多头的 每个头的值向量都有差别 今天就不讲了

### 2.2多层感知机(对应FFN)

MLP与门 加入新的相关元素强化token特征

![image-20250307075054434](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307075054434.png)

最后的最后 我们一层一层迭代 然后就得到最终街工了

## 3 Stable Diffusion原理讲解

![img](https://pic3.zhimg.com/v2-9a4fed959f7750d50aea98a5eb7df3ca_1440w.jpg)

![img](https://i1.hdslb.com/bfs/article/e541253f8201748cffeb3850ffeb2a4bbe866f7f.png@1192w.webp)

### 3.0 扩散模型

什么是扩散模型呢 直白一点说就是降噪————还原的过程

### 3.1 clip

这里运用的就是Transformer 把我们输入的文字转化成生成图片的condition（条件）

通过大量训练 让文字狗和图像狗有关联

![img](https://picx.zhimg.com/v2-6fcd9e16204fd7a457b61adada425883_1440w.jpg)

###  3.2 lantent 潜在空间

![img](https://pic2.zhimg.com/v2-997485f09e31ce6b1fd39bb96ba76fcf_1440w.jpg)

三维的椅子保留特征压缩成二维的图 但是你还能认出来

![image-20250307112017518](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307112017518.png)

总而言之就是保留特征 降低维度

###  3.2 vae编码和vae解码

![image-20250307112122884](C:\Users\18330\AppData\Roaming\Typora\typora-user-images\image-20250307112122884.png)

vae编码可以把图像保留特征压缩到Lantent潜空间中                                   vae解码可以把被压缩的图像还原

### 3.3 Unet 和Sampler

unet完成加噪和去噪的过程 

其中有我们上文所说的条件起作用，Sampler在图像降噪加噪的细节中起着作用

简而言之 clip通过影响降噪过程来指导unet生成我们想要的图片，二者搭配干活来最终形成我们需要的图片。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e9e66db52f4aaeedfd5e151f993be781.png)

![img](https://pic3.zhimg.com/v2-c1585ef82081f25f7cc1706b398d2ba8_1440w.jpg)

### 3.4 实践环节

让我们在comfuyui中快乐的实践吧。
